{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb23555-0a20-4f3b-a569-7551f0827443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773e431d-5268-434f-99cf-5f0013117df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_data = \"../data/raw/df_final_demo.csv\"\n",
    "experiment_data = \"../data/raw/df_final_experiment_clients.csv\"\n",
    "web_data1 = \"../data/raw/df_final_web_data_pt_1.csv\"\n",
    "web_data2 = \"../data/raw/df_final_web_data_pt_2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69027e2b-f05f-4028-9871-f8d0ffc3ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df = pd.read_csv(client_data)\n",
    "experiment_df = pd.read_csv(experiment_data)\n",
    "web1_df = pd.read_csv(web_data1)\n",
    "web2_df = pd.read_csv(web_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d32452b-d4f2-4837-b49f-25792e2db187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_clean_client_df(client_df = client_df, experiment_df = experiment_df):\n",
    "    ''' Merges client and experiment dataframes and adds balance quartiles ''' \n",
    "    \n",
    "    import pandas as pd\n",
    "    merged_client_df = pd.merge(client_df, experiment_df, on='client_id', how='outer')\n",
    "    client_df_cleaned = merged_client_df[merged_client_df.isnull().sum(axis=1) <= 5]\n",
    "    client_df_cleaned['balance_quartile'] = pd.qcut(client_df_cleaned['bal'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "    return client_df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba5b6ce9-dd10-4977-89ea-0c5e7e7f9afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olgeo\\AppData\\Local\\Temp\\ipykernel_3928\\15114656.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  client_df_cleaned['balance_quartile'] = pd.qcut(client_df_cleaned['bal'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n"
     ]
    }
   ],
   "source": [
    "client_df_cleaned = merge_and_clean_client_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b910ab4a-b16e-477f-ac6a-df5f1d402bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df_cleaned.to_csv('../data/clean/clean_client_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c5759af-45ad-4d92-8ef3-83f92164e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_clean_web_df(web1_df = web1_df, web2_df = web2_df, experiment_df = experiment_df):\n",
    "    '''Combines web_data together and merges with experiment data\n",
    "    Gets date_time into appropriate format\n",
    "    Sorts dataframe by time within each visit\n",
    "    Drops web data without distinction between Control/Test''' \n",
    "    import pandas as pd\n",
    "    web_df = pd.concat([web1_df, web2_df], axis=0, ignore_index=True)\n",
    "    web_exp_df = pd.merge(web_df, experiment_df, on='client_id', how='right')\n",
    "    web_exp_df['date_time'] = pd.to_datetime(web_exp_df['date_time'], format='%d/%m/%y %H:%M:%S')\n",
    "    web_exp_df = web_exp_df.sort_values(by=['client_id', 'visit_id', 'date_time'])\n",
    "    web_exp_df = web_exp_df.dropna(subset=['Variation'])\n",
    "    return (web_exp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ad5e51c-46cc-4d67-ab39-a5253ab57b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_exp_df = merge_and_clean_web_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af1c44d2-c8cc-46ba-8629-dcf13ed6c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    ''' Removes duplicated \"start\" and \"confirm\" steps, only keeping the last in each visit ''' \n",
    "    new_df = df.copy()\n",
    "    \n",
    "    non_start_df = new_df[new_df['process_step'] != 'start']\n",
    "    filt_start = new_df[new_df['process_step'] == 'start'].drop_duplicates(subset=['visit_id'], keep='last')\n",
    "    new_df = pd.concat([non_start_df, filt_start])\n",
    "    new_df = new_df.sort_values(by=['client_id', 'visit_id', 'date_time'])\n",
    "    \n",
    "    non_confirm_df = new_df[new_df['process_step'] != 'confirm']\n",
    "    filt_confirm = new_df[new_df['process_step'] == 'confirm'].drop_duplicates(subset=['visit_id'], keep='last')\n",
    "\n",
    "    new_df = pd.concat([non_confirm_df, filt_confirm])\n",
    "    new_df = new_df.sort_values(by=['client_id', 'visit_id', 'date_time'])\n",
    "    return(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa1ec525-7009-44df-a6ef-629b0d44269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def step_checks(df):\n",
    "    ''' Adds columns to dataframe detailing if the step successfully proceeded to the next step,\n",
    "    if the step was the final one in the visit, or if the step was an error (went back a stage)'''\n",
    "    \n",
    "    new_df = df.copy()\n",
    "    new_df\n",
    "    new_df = new_df.sort_values(by=['client_id', 'visit_id', 'date_time'])\n",
    "\n",
    "    #Adds a column to say if that step is the final step of the visit\n",
    "    new_df['visit_final_step'] = new_df['visit_id'] != new_df['visit_id'].shift(-1)\n",
    "\n",
    "    #Adds a column for the duration (in seconds) of each step\n",
    "    new_df['step_duration'] = (new_df['date_time'].shift(-1) - new_df['date_time']).dt.total_seconds()\n",
    "    new_df.loc[new_df['visit_final_step'] == True, 'step_duration'] = np.nan\n",
    "\n",
    "    step_order = ['start', 'step_1', 'step_2', 'step_3', 'confirm']\n",
    "    next_step = {'start': 'step_1', 'step_1': 'step_2', 'step_2': 'step_3', 'step_3': 'confirm'}\n",
    "\n",
    "    #Adds \"next_process_step\" column with the step from the following row\n",
    "    new_df['next_process_step'] = new_df['process_step'].shift(-1)\n",
    "    \n",
    "    #Adds \"step_proceeds\" column which checks if the next step is the same visit and moved forward a step\n",
    "    new_df['step_proceeds'] = new_df.apply(\n",
    "        lambda row: row['next_process_step'] == next_step.get(row['process_step'], None),\n",
    "        axis=1\n",
    "    )\n",
    "    new_df.loc[new_df['visit_final_step'] == True, 'step_proceeds'] = False\n",
    "\n",
    "    #Adds \"step_error\" column which checks if the next step is the same visit and moved back a step\n",
    "    new_df['step_error'] = new_df.apply(\n",
    "        lambda row: row['process_step'] == next_step.get(row['next_process_step'], None),\n",
    "        axis=1\n",
    "    )\n",
    "    new_df.loc[new_df['visit_final_step'] == True, 'step_error'] = False\n",
    "\n",
    "    #Removes \"next_process_step\" column with the step from the following row\n",
    "    new_df.drop(columns='next_process_step', inplace=True)\n",
    "    new_df.reset_index(inplace=True)\n",
    "    new_df.drop(columns='index', inplace=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa91b9f5-5571-4144-acb4-92beb2bd5c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = remove_duplicates(web_exp_df)\n",
    "analysis_df = step_checks(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "198c715b-03f9-4080-91ee-157512541f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>step_error</th>\n",
       "      <th>step_proceeds</th>\n",
       "      <th>visit_final_step</th>\n",
       "      <th>step_duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variation</th>\n",
       "      <th>process_step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Control</th>\n",
       "      <th>confirm</th>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.963998</td>\n",
       "      <td>221.454861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683218</td>\n",
       "      <td>0.312277</td>\n",
       "      <td>39.414676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step_1</th>\n",
       "      <td>0.069705</td>\n",
       "      <td>0.752697</td>\n",
       "      <td>0.117972</td>\n",
       "      <td>55.387458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step_2</th>\n",
       "      <td>0.055088</td>\n",
       "      <td>0.821718</td>\n",
       "      <td>0.056440</td>\n",
       "      <td>94.312098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step_3</th>\n",
       "      <td>0.103970</td>\n",
       "      <td>0.666243</td>\n",
       "      <td>0.097214</td>\n",
       "      <td>146.744545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Test</th>\n",
       "      <th>confirm</th>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987639</td>\n",
       "      <td>192.455224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.706529</td>\n",
       "      <td>0.285555</td>\n",
       "      <td>32.375201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step_1</th>\n",
       "      <td>0.129101</td>\n",
       "      <td>0.709709</td>\n",
       "      <td>0.080943</td>\n",
       "      <td>72.090036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step_2</th>\n",
       "      <td>0.106102</td>\n",
       "      <td>0.780890</td>\n",
       "      <td>0.042822</td>\n",
       "      <td>91.990796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step_3</th>\n",
       "      <td>0.088592</td>\n",
       "      <td>0.704681</td>\n",
       "      <td>0.072218</td>\n",
       "      <td>165.050533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        step_error  step_proceeds  visit_final_step  \\\n",
       "Variation process_step                                                \n",
       "Control   confirm         0.000063       0.000000          0.963998   \n",
       "          start           0.000000       0.683218          0.312277   \n",
       "          step_1          0.069705       0.752697          0.117972   \n",
       "          step_2          0.055088       0.821718          0.056440   \n",
       "          step_3          0.103970       0.666243          0.097214   \n",
       "Test      confirm         0.000138       0.000000          0.987639   \n",
       "          start           0.000000       0.706529          0.285555   \n",
       "          step_1          0.129101       0.709709          0.080943   \n",
       "          step_2          0.106102       0.780890          0.042822   \n",
       "          step_3          0.088592       0.704681          0.072218   \n",
       "\n",
       "                        step_duration  \n",
       "Variation process_step                 \n",
       "Control   confirm          221.454861  \n",
       "          start             39.414676  \n",
       "          step_1            55.387458  \n",
       "          step_2            94.312098  \n",
       "          step_3           146.744545  \n",
       "Test      confirm          192.455224  \n",
       "          start             32.375201  \n",
       "          step_1            72.090036  \n",
       "          step_2            91.990796  \n",
       "          step_3           165.050533  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_df.groupby(['Variation','process_step'])[['step_error', 'step_proceeds', 'visit_final_step','step_duration']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cad0416f-3897-4c86-b032-bf4f6595834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis_df.to_csv('../data/clean/analysis_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8378f8c8-db84-4970-b87c-46c9be947d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier_visits(df):\n",
    "    ''' Within each Variation and step removes visits containing steps of outlier durations\n",
    "    outliers defined as being 1.5 * IQR below Q1 or above Q3'''\n",
    "    def duration_outliers(group):\n",
    "        Q1 = group['step_duration'].quantile(0.25)\n",
    "        Q3 = group['step_duration'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Filter rows where step_duration is an outlier\n",
    "        outliers = group[(group['step_duration'] < lower_bound) | (group['step_duration'] > upper_bound)]\n",
    "        return outliers\n",
    "\n",
    "    outliers_df = df.groupby(['Variation', 'process_step'], group_keys=False).apply(duration_outliers)\n",
    "\n",
    "    outlier_visits = list(outliers_df['visit_id'].unique())\n",
    "\n",
    "    filt_df = df[~df['visit_id'].isin(outlier_visits)]\n",
    "    \n",
    "    return filt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "371d93b4-b147-446c-82ad-caee34f37a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olgeo\\AppData\\Local\\Temp\\ipykernel_3928\\3027866023.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  outliers_df = df.groupby(['Variation', 'process_step'], group_keys=False).apply(duration_outliers)\n"
     ]
    }
   ],
   "source": [
    "no_outlier_df = remove_outlier_visits(analysis_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77019cf3-4cea-4723-9951-41318d51c305",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_outlier_df.to_csv('../data/clean/removed_outliers_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7defdcf-d673-4d16-b3a4-e7eef2272a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def successful_visit_col(df=analysis_df):\n",
    "    ''' Adds a column to the dataframe stating if the visit was a success (Processed every step from start to confirm) '''\n",
    "    analysis_df = df.copy()\n",
    "    start_visit_ids = list(analysis_df[(analysis_df['process_step'] == 'start') & (analysis_df['step_proceeds'] == True)]['visit_id'])\n",
    "    step_1_visit_ids = list(analysis_df[(analysis_df['process_step'] == 'step_1') & (analysis_df['step_proceeds'] == True)]['visit_id'])\n",
    "    step_2_visit_ids = list(analysis_df[(analysis_df['process_step'] == 'step_2') & (analysis_df['step_proceeds'] == True)]['visit_id'])\n",
    "    step_3_visit_ids = list(analysis_df[(analysis_df['process_step'] == 'step_3') & (analysis_df['step_proceeds'] == True)]['visit_id'])\n",
    "    confirm_visit_ids = list(analysis_df[analysis_df['process_step']=='confirm']['visit_id'])\n",
    "    successful_visits = list(set(start_visit_ids) & set(step_1_visit_ids) & set(step_2_visit_ids) & set(step_3_visit_ids) & set(confirm_visit_ids))\n",
    "    analysis_df['successful_visit'] = analysis_df['visit_id'].isin(successful_visits)\n",
    "    return analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8f6e25-36b0-4475-ae74-a40624717185",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_visit_col = successful_visit_col(no_outlier_df)\n",
    "\n",
    "extra_visit_col.to_csv('../data/clean/data_extra_col.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
